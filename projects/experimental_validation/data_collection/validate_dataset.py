#!/usr/bin/env python3
"""
æ•°æ®é›†éªŒè¯è„šæœ¬

æœ¬è„šæœ¬éªŒè¯å¤„ç†åçš„æ•°æ®é›†çš„è´¨é‡å’Œä¸€è‡´æ€§ï¼ŒåŒ…æ‹¬:
1. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
2. æ ¼å¼åˆè§„æ€§æ£€æŸ¥
3. ç‰©ç†åˆç†æ€§æ£€æŸ¥
4. ç”ŸæˆéªŒè¯æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•:
    python validate_dataset.py --experiment_id exp_001 --data_dir data/processed
"""

import os
import sys
import json
import argparse
import numpy as np
from pathlib import Path
import csv
from datetime import datetime


class DatasetValidator:
    """æ•°æ®é›†éªŒè¯å™¨"""
    
    def __init__(self, experiment_id, data_dir="data/processed"):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            experiment_id: å®éªŒID (å¦‚ "exp_001")
            data_dir: æ•°æ®ç›®å½• (åŒ…å«å¤„ç†åçš„æ•°æ®)
        """
        self.experiment_id = experiment_id
        self.data_dir = Path(data_dir) / experiment_id
        
        # éªŒè¯ç›®å½•æ˜¯å¦å­˜åœ¨
        if not self.data_dir.exists():
            print(f"é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
            raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
        
        # éªŒè¯ç»“æœå­˜å‚¨
        self.validation_results = {
            "experiment_id": experiment_id,
            "validation_time": datetime.now().isoformat(),
            "checks": {},
            "summary": {
                "total_checks": 0,
                "passed_checks": 0,
                "failed_checks": 0,
                "warnings": 0
            },
            "issues": []
        }
    
    def check_directory_structure(self):
        """æ£€æŸ¥ç›®å½•ç»“æ„"""
        check_name = "directory_structure"
        print(f"æ£€æŸ¥: {check_name}")
        
        required_dirs = [
            "displacement_fields",
            "marker_positions",
            "force_estimates",
            "validation_results"
        ]
        
        missing_dirs = []
        for dir_name in required_dirs:
            dir_path = self.data_dir / dir_name
            if not dir_path.exists():
                missing_dirs.append(dir_name)
        
        if missing_dirs:
            result = {
                "status": "FAILED",
                "message": f"ç¼ºå¤±ç›®å½•: {', '.join(missing_dirs)}",
                "missing_dirs": missing_dirs
            }
            self.validation_results["issues"].append({
                "type": "missing_directory",
                "directories": missing_dirs,
                "severity": "high"
            })
        else:
            result = {
                "status": "PASSED",
                "message": "ç›®å½•ç»“æ„å®Œæ•´"
            }
        
        self.validation_results["checks"][check_name] = result
        return result
    
    def check_displacement_fields(self):
        """æ£€æŸ¥ä½ç§»åœºæ•°æ®"""
        check_name = "displacement_fields"
        print(f"æ£€æŸ¥: {check_name}")
        
        disp_dir = self.data_dir / "displacement_fields"
        if not disp_dir.exists():
            result = {
                "status": "FAILED",
                "message": "ä½ç§»åœºç›®å½•ä¸å­˜åœ¨",
                "files_found": 0
            }
            self.validation_results["checks"][check_name] = result
            return result
        
        # æŸ¥æ‰¾ä½ç§»åœºæ–‡ä»¶
        disp_files = list(disp_dir.glob("disp_*.npy"))
        
        if not disp_files:
            result = {
                "status": "FAILED",
                "message": "æœªæ‰¾åˆ°ä½ç§»åœºæ–‡ä»¶",
                "files_found": 0
            }
            self.validation_results["issues"].append({
                "type": "no_displacement_files",
                "severity": "high"
            })
        else:
            # æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹
            valid_files = 0
            file_stats = []
            
            for i, file_path in enumerate(disp_files[:5]):  # æ£€æŸ¥å‰5ä¸ªæ–‡ä»¶
                try:
                    disp = np.load(str(file_path))
                    
                    # æ£€æŸ¥æ•°ç»„å½¢çŠ¶å’Œç±»å‹
                    if disp.ndim == 2 and disp.shape[1] == 2:
                        stats = {
                            "file": file_path.name,
                            "shape": disp.shape,
                            "dtype": str(disp.dtype),
                            "min": float(np.min(disp)),
                            "max": float(np.max(disp)),
                            "mean": float(np.mean(disp)),
                            "std": float(np.std(disp))
                        }
                        file_stats.append(stats)
                        valid_files += 1
                    else:
                        self.validation_results["issues"].append({
                            "type": "invalid_displacement_shape",
                            "file": file_path.name,
                            "shape": disp.shape,
                            "expected_shape": "(N, 2)",
                            "severity": "medium"
                        })
                        
                except Exception as e:
                    self.validation_results["issues"].append({
                        "type": "displacement_file_error",
                        "file": file_path.name,
                        "error": str(e),
                        "severity": "medium"
                    })
            
            # æ£€æŸ¥ä½ç§»å€¼çš„ç‰©ç†åˆç†æ€§ (å•ä½: mm)
            # å…¸å‹ä½ç§»åº”è¯¥åœ¨0-5mmèŒƒå›´å†…
            physical_issues = 0
            for stats in file_stats:
                max_abs = max(abs(stats["min"]), abs(stats["max"]))
                if max_abs > 10.0:  # ä½ç§»è¿‡å¤§è­¦å‘Š
                    self.validation_results["issues"].append({
                        "type": "large_displacement",
                        "file": stats["file"],
                        "max_abs_displacement_mm": max_abs,
                        "threshold_mm": 10.0,
                        "severity": "low"
                    })
                    physical_issues += 1
            
            result = {
                "status": "PASSED" if valid_files > 0 else "FAILED",
                "message": f"æ‰¾åˆ° {len(disp_files)} ä¸ªä½ç§»åœºæ–‡ä»¶ï¼Œ{valid_files} ä¸ªæœ‰æ•ˆ",
                "files_found": len(disp_files),
                "valid_files": valid_files,
                "sample_stats": file_stats[:3] if file_stats else [],
                "physical_issues": physical_issues
            }
        
        self.validation_results["checks"][check_name] = result
        return result
    
    def check_marker_positions(self):
        """æ£€æŸ¥æ ‡è®°ç‚¹ä½ç½®æ•°æ®"""
        check_name = "marker_positions"
        print(f"æ£€æŸ¥: {check_name}")
        
        markers_dir = self.data_dir / "marker_positions"
        if not markers_dir.exists():
            result = {
                "status": "FAILED",
                "message": "æ ‡è®°ç‚¹ä½ç½®ç›®å½•ä¸å­˜åœ¨",
                "files_found": 0
            }
            self.validation_results["checks"][check_name] = result
            return result
        
        # æŸ¥æ‰¾æ ‡è®°ç‚¹æ–‡ä»¶
        marker_files = list(markers_dir.glob("*.npy"))
        
        # æ£€æŸ¥å‚è€ƒæ ‡è®°ç‚¹æ–‡ä»¶
        ref_marker_file = markers_dir / "reference_markers.npy"
        has_reference = ref_marker_file.exists()
        
        if not marker_files:
            result = {
                "status": "FAILED",
                "message": "æœªæ‰¾åˆ°æ ‡è®°ç‚¹æ–‡ä»¶",
                "files_found": 0,
                "has_reference": has_reference
            }
            self.validation_results["issues"].append({
                "type": "no_marker_files",
                "severity": "high"
            })
        else:
            valid_files = 0
            file_stats = []
            
            # æ£€æŸ¥å‚è€ƒæ ‡è®°ç‚¹
            if has_reference:
                try:
                    ref_markers = np.load(str(ref_marker_file))
                    if ref_markers.ndim == 2 and ref_markers.shape[1] == 2:
                        ref_stats = {
                            "file": "reference_markers.npy",
                            "shape": ref_markers.shape,
                            "num_markers": ref_markers.shape[0],
                            "x_range": [float(np.min(ref_markers[:, 0])), 
                                       float(np.max(ref_markers[:, 0]))],
                            "y_range": [float(np.min(ref_markers[:, 1])), 
                                       float(np.max(ref_markers[:, 1]))]
                        }
                        file_stats.append(ref_stats)
                        valid_files += 1
                        
                        # æ£€æŸ¥æ ‡è®°ç‚¹é—´è·æ˜¯å¦åˆç†
                        if ref_markers.shape[0] > 1:
                            from scipy.spatial import distance_matrix
                            try:
                                dists = distance_matrix(ref_markers, ref_markers)
                                # è·å–æœ€å°éé›¶è·ç¦»
                                dists[dists == 0] = np.inf
                                min_dist = np.min(dists)
                                if min_dist < 5.0:  # æ ‡è®°ç‚¹é—´è·è¿‡å°
                                    self.validation_results["issues"].append({
                                        "type": "small_marker_spacing",
                                        "file": "reference_markers.npy",
                                        "min_spacing_px": min_dist,
                                        "threshold_px": 5.0,
                                        "severity": "medium"
                                    })
                            except:
                                pass  # è·³è¿‡è·ç¦»è®¡ç®—é”™è¯¯
                    else:
                        self.validation_results["issues"].append({
                            "type": "invalid_reference_markers",
                            "file": "reference_markers.npy",
                            "shape": ref_markers.shape,
                            "expected_shape": "(N, 2)",
                            "severity": "high"
                        })
                        
                except Exception as e:
                    self.validation_results["issues"].append({
                        "type": "reference_marker_error",
                        "file": "reference_markers.npy",
                        "error": str(e),
                        "severity": "high"
                    })
            
            # æ£€æŸ¥å…¶ä»–æ ‡è®°ç‚¹æ–‡ä»¶
            for file_path in marker_files:
                if file_path.name == "reference_markers.npy":
                    continue
                
                try:
                    markers = np.load(str(file_path))
                    if markers.ndim == 2 and markers.shape[1] == 2:
                        valid_files += 1
                except Exception as e:
                    self.validation_results["issues"].append({
                        "type": "marker_file_error",
                        "file": file_path.name,
                        "error": str(e),
                        "severity": "medium"
                    })
            
            result = {
                "status": "PASSED" if valid_files > 0 else "FAILED",
                "message": f"æ‰¾åˆ° {len(marker_files)} ä¸ªæ ‡è®°ç‚¹æ–‡ä»¶ï¼Œ{valid_files} ä¸ªæœ‰æ•ˆ",
                "files_found": len(marker_files),
                "valid_files": valid_files,
                "has_reference": has_reference,
                "reference_stats": file_stats[0] if file_stats else None
            }
        
        self.validation_results["checks"][check_name] = result
        return result
    
    def check_force_estimates(self):
        """æ£€æŸ¥åŠ›ä¼°è®¡æ•°æ®"""
        check_name = "force_estimates"
        print(f"æ£€æŸ¥: {check_name}")
        
        force_dir = self.data_dir / "force_estimates"
        if not force_dir.exists():
            result = {
                "status": "FAILED",
                "message": "åŠ›ä¼°è®¡ç›®å½•ä¸å­˜åœ¨",
                "files_found": 0
            }
            self.validation_results["checks"][check_name] = result
            return result
        
        # æ£€æŸ¥CSVæ–‡ä»¶
        csv_file = force_dir / "force_estimates.csv"
        json_file = force_dir / "force_estimates.json"
        
        files_exist = {
            "csv": csv_file.exists(),
            "json": json_file.exists()
        }
        
        if not files_exist["csv"] and not files_exist["json"]:
            result = {
                "status": "FAILED",
                "message": "æœªæ‰¾åˆ°åŠ›ä¼°è®¡æ–‡ä»¶",
                "files_found": 0
            }
            self.validation_results["issues"].append({
                "type": "no_force_estimate_files",
                "severity": "medium"
            })
            self.validation_results["checks"][check_name] = result
            return result
        
        # æ£€æŸ¥CSVæ–‡ä»¶å†…å®¹
        csv_data = None
        if files_exist["csv"]:
            try:
                with open(csv_file, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    rows = list(reader)
                    
                    if rows:
                        # æ£€æŸ¥åˆ—å
                        expected_cols = ["frame_id", "force_x_n", "force_y_n", "force_z_n"]
                        actual_cols = list(rows[0].keys())
                        missing_cols = [col for col in expected_cols if col not in actual_cols]
                        
                        if missing_cols:
                            self.validation_results["issues"].append({
                                "type": "missing_force_columns",
                                "file": "force_estimates.csv",
                                "missing_columns": missing_cols,
                                "severity": "medium"
                            })
                        
                        # æ£€æŸ¥æ•°æ®å€¼
                        force_values = []
                        for row in rows:
                            try:
                                fz = float(row.get("force_z_n", 0))
                                force_values.append(fz)
                            except:
                                pass
                        
                        if force_values:
                            stats = {
                                "num_records": len(rows),
                                "force_z_stats": {
                                    "min": float(np.min(force_values)),
                                    "max": float(np.max(force_values)),
                                    "mean": float(np.mean(force_values)),
                                    "std": float(np.std(force_values))
                                }
                            }
                            csv_data = stats
                            
                            # æ£€æŸ¥åŠ›å€¼çš„ç‰©ç†åˆç†æ€§ (å•ä½: N)
                            # å…¸å‹æ¥è§¦åŠ›åº”è¯¥åœ¨0-50NèŒƒå›´å†…
                            max_abs = max(abs(stats["force_z_stats"]["min"]), 
                                         abs(stats["force_z_stats"]["max"]))
                            if max_abs > 100.0:  # åŠ›å€¼è¿‡å¤§è­¦å‘Š
                                self.validation_results["issues"].append({
                                    "type": "large_force_value",
                                    "file": "force_estimates.csv",
                                    "max_abs_force_n": max_abs,
                                    "threshold_n": 100.0,
                                    "severity": "low"
                                })
                            
                    else:
                        self.validation_results["issues"].append({
                            "type": "empty_force_csv",
                            "file": "force_estimates.csv",
                            "severity": "medium"
                        })
                        
            except Exception as e:
                self.validation_results["issues"].append({
                    "type": "force_csv_error",
                    "file": "force_estimates.csv",
                    "error": str(e),
                    "severity": "medium"
                })
        
        result = {
            "status": "PASSED" if (files_exist["csv"] or files_exist["json"]) else "FAILED",
            "message": f"åŠ›ä¼°è®¡æ–‡ä»¶: CSV={files_exist['csv']}, JSON={files_exist['json']}",
            "files_exist": files_exist,
            "csv_stats": csv_data
        }
        
        self.validation_results["checks"][check_name] = result
        return result
    
    def check_validation_results(self):
        """æ£€æŸ¥éªŒè¯ç»“æœ"""
        check_name = "validation_results"
        print(f"æ£€æŸ¥: {check_name}")
        
        validation_dir = self.data_dir / "validation_results"
        if not validation_dir.exists():
            result = {
                "status": "WARNING",
                "message": "éªŒè¯ç»“æœç›®å½•ä¸å­˜åœ¨",
                "files_found": 0
            }
            self.validation_results["checks"][check_name] = result
            return result
        
        # æŸ¥æ‰¾éªŒè¯æŠ¥å‘Š
        report_files = list(validation_dir.glob("*.md")) + list(validation_dir.glob("*.json"))
        
        if not report_files:
            result = {
                "status": "WARNING",
                "message": "æœªæ‰¾åˆ°éªŒè¯æŠ¥å‘Šæ–‡ä»¶",
                "files_found": 0
            }
            self.validation_results["issues"].append({
                "type": "no_validation_reports",
                "severity": "low"
            })
        else:
            result = {
                "status": "PASSED",
                "message": f"æ‰¾åˆ° {len(report_files)} ä¸ªéªŒè¯æŠ¥å‘Šæ–‡ä»¶",
                "files_found": len(report_files),
                "file_list": [f.name for f in report_files]
            }
        
        self.validation_results["checks"][check_name] = result
        return result
    
    def check_data_consistency(self):
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        check_name = "data_consistency"
        print(f"æ£€æŸ¥: {check_name}")
        
        issues = []
        
        # æ£€æŸ¥ä½ç§»åœºå’Œæ ‡è®°ç‚¹æ–‡ä»¶æ•°é‡æ˜¯å¦åŒ¹é…
        disp_dir = self.data_dir / "displacement_fields"
        markers_dir = self.data_dir / "marker_positions"
        
        if disp_dir.exists() and markers_dir.exists():
            disp_files = list(disp_dir.glob("disp_*.npy"))
            marker_files = [f for f in markers_dir.glob("*.npy") 
                           if f.name != "reference_markers.npy"]
            
            if disp_files and marker_files:
                num_disp = len(disp_files)
                num_markers = len(marker_files)
                
                if num_disp != num_markers:
                    issues.append({
                        "type": "file_count_mismatch",
                        "displacement_files": num_disp,
                        "marker_files": num_markers,
                        "difference": abs(num_disp - num_markers),
                        "severity": "medium"
                    })
                
                # æ£€æŸ¥æ–‡ä»¶åå¯¹åº”å…³ç³»
                disp_indices = []
                for f in disp_files:
                    try:
                        idx = int(f.stem.split('_')[1])
                        disp_indices.append(idx)
                    except:
                        pass
                
                marker_indices = []
                for f in marker_files:
                    try:
                        idx = int(f.stem.split('_')[1])
                        marker_indices.append(idx)
                    except:
                        pass
                
                if disp_indices and marker_indices:
                    missing_in_markers = set(disp_indices) - set(marker_indices)
                    missing_in_disp = set(marker_indices) - set(disp_indices)
                    
                    if missing_in_markers:
                        issues.append({
                            "type": "missing_marker_files",
                            "missing_indices": list(missing_in_markers),
                            "severity": "medium"
                        })
                    
                    if missing_in_disp:
                        issues.append({
                            "type": "missing_displacement_files",
                            "missing_indices": list(missing_in_disp),
                            "severity": "medium"
                        })
        
        # æ£€æŸ¥ä½ç§»åœºå’ŒåŠ›ä¼°è®¡çš„å¸§æ•°åŒ¹é…
        force_csv = self.data_dir / "force_estimates" / "force_estimates.csv"
        if disp_dir.exists() and force_csv.exists():
            try:
                disp_files = list(disp_dir.glob("disp_*.npy"))
                with open(force_csv, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    force_rows = list(reader)
                
                if disp_files and force_rows:
                    if len(disp_files) != len(force_rows):
                        issues.append({
                            "type": "displacement_force_count_mismatch",
                            "displacement_files": len(disp_files),
                            "force_records": len(force_rows),
                            "difference": abs(len(disp_files) - len(force_rows)),
                            "severity": "medium"
                        })
            except:
                pass  # è·³è¿‡é”™è¯¯
        
        result = {
            "status": "PASSED" if not issues else "WARNING",
            "message": f"æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥: å‘ç° {len(issues)} ä¸ªé—®é¢˜",
            "issues_found": len(issues),
            "issues": issues
        }
        
        # æ·»åŠ é—®é¢˜åˆ°æ€»åˆ—è¡¨
        for issue in issues:
            self.validation_results["issues"].append(issue)
        
        self.validation_results["checks"][check_name] = result
        return result
    
    def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print(f"=== æ•°æ®é›†éªŒè¯å¼€å§‹ ===")
        print(f"å®éªŒID: {self.experiment_id}")
        print(f"æ•°æ®ç›®å½•: {self.data_dir}")
        print()
        
        checks = [
            self.check_directory_structure,
            self.check_displacement_fields,
            self.check_marker_positions,
            self.check_force_estimates,
            self.check_validation_results,
            self.check_data_consistency
        ]
        
        for check_func in checks:
            try:
                result = check_func()
                
                # æ›´æ–°æ‘˜è¦ç»Ÿè®¡
                self.validation_results["summary"]["total_checks"] += 1
                status = result.get("status", "UNKNOWN")
                
                if status == "PASSED":
                    self.validation_results["summary"]["passed_checks"] += 1
                elif status == "FAILED":
                    self.validation_results["summary"]["failed_checks"] += 1
                elif status == "WARNING":
                    self.validation_results["summary"]["warnings"] += 1
                
                print(f"  {status}: {result.get('message', '')}")
                
            except Exception as e:
                print(f"  æ£€æŸ¥å¤±è´¥: {e}")
                self.validation_results["summary"]["total_checks"] += 1
                self.validation_results["summary"]["failed_checks"] += 1
        
        # ç”Ÿæˆæ€»ä½“çŠ¶æ€
        total = self.validation_results["summary"]["total_checks"]
        passed = self.validation_results["summary"]["passed_checks"]
        failed = self.validation_results["summary"]["failed_checks"]
        
        if failed == 0:
            overall_status = "PASSED"
        elif failed / total < 0.3:  # å°‘äº30%å¤±è´¥
            overall_status = "WARNING"
        else:
            overall_status = "FAILED"
        
        self.validation_results["overall_status"] = overall_status
        
        print(f"\n=== éªŒè¯å®Œæˆ ===")
        print(f"æ€»ä½“çŠ¶æ€: {overall_status}")
        print(f"æ£€æŸ¥ç»Ÿè®¡: {passed}/{total} é€šè¿‡, {failed} å¤±è´¥, "
              f"{self.validation_results['summary']['warnings']} è­¦å‘Š")
        
        if self.validation_results["issues"]:
            print(f"å‘ç°çš„é—®é¢˜: {len(self.validation_results['issues'])}")
            for i, issue in enumerate(self.validation_results["issues"][:5]):  # æ˜¾ç¤ºå‰5ä¸ª
                print(f"  {i+1}. [{issue.get('severity', 'unknown')}] {issue.get('type', 'unknown')}")
        
        return overall_status
    
    def generate_report(self, output_dir=None):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        if output_dir is None:
            output_dir = self.data_dir / "validation_results"
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True, parents=True)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        report_path = output_dir / "dataset_validation_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# æ•°æ®é›†éªŒè¯æŠ¥å‘Š\n\n")
            
            # åŸºæœ¬ä¿¡æ¯
            f.write("## åŸºæœ¬ä¿¡æ¯\n")
            f.write(f"- **å®éªŒID**: {self.validation_results['experiment_id']}\n")
            f.write(f"- **éªŒè¯æ—¶é—´**: {self.validation_results['validation_time']}\n")
            f.write(f"- **æ•°æ®ç›®å½•**: {self.data_dir}\n")
            f.write(f"- **æ€»ä½“çŠ¶æ€**: **{self.validation_results['overall_status']}**\n\n")
            
            # æ£€æŸ¥ç»Ÿè®¡
            f.write("## æ£€æŸ¥ç»Ÿè®¡\n")
            summary = self.validation_results["summary"]
            f.write(f"- **æ€»æ£€æŸ¥æ•°**: {summary['total_checks']}\n")
            f.write(f"- **é€šè¿‡**: {summary['passed_checks']}\n")
            f.write(f"- **å¤±è´¥**: {summary['failed_checks']}\n")
            f.write(f"- **è­¦å‘Š**: {summary['warnings']}\n\n")
            
            # è¯¦ç»†æ£€æŸ¥ç»“æœ
            f.write("## è¯¦ç»†æ£€æŸ¥ç»“æœ\n")
            for check_name, result in self.validation_results["checks"].items():
                status = result.get("status", "UNKNOWN")
                status_emoji = "âœ…" if status == "PASSED" else "âš ï¸" if status == "WARNING" else "âŒ"
                f.write(f"\n### {check_name.replace('_', ' ').title()}\n")
                f.write(f"{status_emoji} **çŠ¶æ€**: {status}\n")
                f.write(f"**æ¶ˆæ¯**: {result.get('message', '')}\n")
                
                # æ·»åŠ è¯¦ç»†ä¿¡æ¯
                for key, value in result.items():
                    if key not in ["status", "message"] and value:
                        f.write(f"- **{key}**: {value}\n")
            
            # é—®é¢˜åˆ—è¡¨
            if self.validation_results["issues"]:
                f.write("\n## å‘ç°çš„é—®é¢˜\n")
                f.write(f"å…±å‘ç° {len(self.validation_results['issues'])} ä¸ªé—®é¢˜:\n\n")
                
                for i, issue in enumerate(self.validation_results["issues"]):
                    severity = issue.get("severity", "unknown")
                    severity_emoji = {
                        "high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"
                    }.get(severity, "âšª")
                    
                    f.write(f"{i+1}. {severity_emoji} **[{severity.upper()}] {issue.get('type', 'unknown')}**\n")
                    
                    for key, value in issue.items():
                        if key not in ["type", "severity"]:
                            f.write(f"   - {key}: {value}\n")
            
            # å»ºè®®
            f.write("\n## å»ºè®®ä¸ä¸‹ä¸€æ­¥\n")
            
            if self.validation_results["overall_status"] == "PASSED":
                f.write("æ•°æ®é›†éªŒè¯é€šè¿‡ï¼Œå¯ä»¥ç”¨äºç®—æ³•è®­ç»ƒå’ŒéªŒè¯ã€‚\n")
            elif self.validation_results["overall_status"] == "WARNING":
                f.write("æ•°æ®é›†æœ‰è­¦å‘Šï¼Œå»ºè®®æ£€æŸ¥å¹¶ä¿®å¤é—®é¢˜åå†ä½¿ç”¨ã€‚\n")
            else:
                f.write("æ•°æ®é›†éªŒè¯å¤±è´¥ï¼Œéœ€è¦ä¿®å¤å…³é”®é—®é¢˜åæ‰èƒ½ä½¿ç”¨ã€‚\n")
            
            f.write("\n### ä¸‹ä¸€æ­¥æ“ä½œ\n")
            f.write("1. æ ¹æ®é—®é¢˜åˆ—è¡¨ä¿®å¤æ•°æ®é—®é¢˜\n")
            f.write("2. é‡æ–°è¿è¡Œæ•°æ®æ”¶é›†å’Œå¤„ç†æµç¨‹\n")
            f.write("3. é‡æ–°è¿è¡Œæœ¬éªŒè¯è„šæœ¬\n")
            f.write("4. ä½¿ç”¨éªŒè¯é€šè¿‡çš„æ•°æ®é›†è¿›è¡Œç®—æ³•è®­ç»ƒå’Œæµ‹è¯•\n")
        
        print(f"éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        
        # ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†ç»“æœ
        json_path = output_dir / "dataset_validation_results.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.validation_results, f, indent=2, default=str)
        
        print(f"è¯¦ç»†ç»“æœå·²ä¿å­˜: {json_path}")
        
        return report_path, json_path


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ•°æ®é›†éªŒè¯è„šæœ¬")
    parser.add_argument("--experiment_id", type=str, default="exp_001",
                       help="å®éªŒID (é»˜è®¤: exp_001)")
    parser.add_argument("--data_dir", type=str, default="data/processed",
                       help="æ•°æ®ç›®å½• (é»˜è®¤: data/processed)")
    parser.add_argument("--output_dir", type=str, default=None,
                       help="è¾“å‡ºç›®å½• (é»˜è®¤: <data_dir>/validation_results)")
    parser.add_argument("--skip_report", action="store_true",
                       help="è·³è¿‡æŠ¥å‘Šç”Ÿæˆ")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºéªŒè¯å™¨
        validator = DatasetValidator(
            experiment_id=args.experiment_id,
            data_dir=args.data_dir
        )
        
        # è¿è¡Œæ‰€æœ‰æ£€æŸ¥
        overall_status = validator.run_all_checks()
        
        # ç”ŸæˆæŠ¥å‘Š
        if not args.skip_report:
            print("\nç”ŸæˆéªŒè¯æŠ¥å‘Š...")
            report_path, json_path = validator.generate_report(args.output_dir)
            print(f"æŠ¥å‘Šæ–‡ä»¶: {report_path}")
            print(f"JSONç»“æœ: {json_path}")
        
        # è¿”å›é€€å‡ºç 
        if overall_status == "FAILED":
            print("\næ•°æ®é›†éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®å¤é—®é¢˜ã€‚")
            return 1
        elif overall_status == "WARNING":
            print("\næ•°æ®é›†éªŒè¯æœ‰è­¦å‘Šï¼Œå»ºè®®æ£€æŸ¥é—®é¢˜ã€‚")
            return 0
        else:
            print("\næ•°æ®é›†éªŒè¯é€šè¿‡ã€‚")
            return 0
            
    except Exception as e:
        print(f"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())